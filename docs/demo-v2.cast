{"version": 2, "width": 80, "height": 24}
[0.578, "o", "\u001b[3J\u001b[H\u001b[2J\u001b[1m\u001b[1;37m"]
[0.59, "o", "\r\n  \u2588\u2588\u2557   \u2588\u2588\u2557\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2557   \u2588\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\r\n  \u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2588\u2588\u2557 \u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2550\u2550\u255d\r\n  \u2588\u2588\u2551   \u2588\u2588\u2551\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2557  \u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2551\u2588\u2588\u2554\u2588\u2588\u2588\u2588\u2554\u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2557\r\n  \u255a\u2588\u2588\u2557 \u2588\u2588\u2554\u255d\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2554\u2550\u2550\u255d  \u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2557\u2588\u2588\u2554\u2550\u2550\u2588\u2588\u2551\u2588\u2588\u2551\u255a\u2588\u2588\u2554\u255d\u2588\u2588\u2551\u2588\u2588\u2554\u2550\u2550\u255d\r\n   \u255a\u2588\u2588\u2588\u2588\u2554\u255d \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2554\u255d\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\u2588\u2588\u2551     \u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551  \u2588\u2588\u2551\u2588\u2588\u2551 \u255a\u2550\u255d \u2588\u2588\u2551\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2557\r\n    \u255a\u2550\u2550\u2550\u255d  \u255a\u2550"]
[0.591, "o", "\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u255d \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\u255a\u2550\u255d     \u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d  \u255a\u2550\u255d\u255a\u2550\u255d     \u255a\u2550\u255d\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u255d\r\n\r\n"]
[0.592, "o", "\u001b[0m\u001b[2m  AI-native video editing in the terminal\u001b[0m\r\n\u001b[2m  Mode: dry-run\u001b[0m\r\n\r\n"]
[2.601, "o", "\r\n\u001b[44m\u001b[1;37m                                                                \r\n"]
[2.601, "o", "              ACT 1: One Command Video Production               \r\n                                                                "]
[2.601, "o", "\u001b[0m\r\n\r\n\u001b[2m# One script in, full video out \u2014 a single command produces a finished video\u001b[0m\r\n\r\n"]
[4.113, "o", "\u001b[2m# AI auto-generates: storyboard \u2192 narration \u2192 images \u2192 video \u2192 project file\u001b[0m\r\n\r\n"]
[4.113, "o", "\u001b[0;32m$ vibe ai script-to-video \\\u001b[0m\r\n"]
[4.113, "o", "\u001b[0;32m    \"A 30-second product launch video for an AI video editor. Sce...\" \\\u001b[0m\r\n\u001b[0;32m    --voice rachel \\\u001b[0m\r\n\u001b[0;32m    --image-provider gemini \\\u001b[0m\r\n\u001b[0;32m    --generator kling\u001b[0m\r\n\r\n\u001b[2m# Running pipeline...\u001b[0m\r\n\r\n\u001b[2m  [1/5] Generating storyboard with Claude...\u001b[0m\r\n"]
[4.924, "o", "\u001b[2m        3 scenes, 30s total duration\u001b[0m\r\n"]
[5.237, "o", "\u001b[2m  [2/5] Generating narration with ElevenLabs (voice: rachel)...\u001b[0m\r\n"]
[6.05, "o", "\u001b[2m        scene-1.mp3 (10.2s) scene-2.mp3 (9.8s) scene-3.mp3 (10.0s)\u001b[0m\r\n"]
[6.358, "o", "\u001b[2m  [3/5] Generating images with Gemini...\u001b[0m\r\n"]
[7.172, "o", "\u001b[2m        scene-1.png scene-2.png scene-3.png\u001b[0m\r\n"]
[7.482, "o", "\u001b[2m  [4/5] Generating videos with Kling v2.5...\u001b[0m\r\n"]
[8.295, "o", "\u001b[2m        scene-1.mp4 (10s) scene-2.mp4 (10s) scene-3.mp4 (10s)\u001b[0m\r\n"]
[8.608, "o", "\u001b[2m  [5/5] Assembling project...\u001b[0m\r\n"]
[9.12, "o", "\r\n\u001b[0;32m  Done! Project: my-project.vibe.json\u001b[0m\r\n"]
[9.12, "o", "\u001b[0;32m  Output:  script-to-video-output/final.mp4 (30s, 1080p)\u001b[0m\r\n\r\n\u001b[2m# One text in, finished video out. Storyboard, narration, images, video \u2014 all AI-generated.\u001b[0m\r\n"]
[11.131, "o", "\r\n\u001b[44m\u001b[1;37m                                                                "]
[11.131, "o", "\r\n"]
[11.131, "o", "                  ACT 2: Post-Production Combo                  \r\n                                                                \u001b[0m\r\n\r\n"]
[11.131, "o", "\u001b[2m# 4-hit post-production combo \u2014 denoise \u2192 silence cut \u2192 captions \u2192 fade\u001b[0m\r\n\r\n"]
[12.641, "o", "\u001b[2m# Step 1: Remove audio noise\u001b[0m\r\n"]
[12.641, "o", "\u001b[0;32m$ vibe ai noise-reduce demo-output/sample.mp4 -o demo-output/step1-clean.mp4\u001b[0m\r\n\u001b[2m  (dry-run: skipped)\u001b[0m\r\n\r\n"]
[12.641, "o", "\u001b[2m  Noise profile: -30dB detected\u001b[0m\r\n"]
[12.641, "o", "\u001b[2m  Applied: highpass=200, lowpass=3000, afftdn=nr=20\u001b[0m\r\n"]
[12.641, "o", "\u001b[0;32m  Cleaned: step1-clean.mp4\u001b[0m\r\n"]
[12.641, "o", "\r\n"]
[13.154, "o", "\u001b[2m# Step 2: Auto-cut silent segments\u001b[0m\r\n"]
[13.154, "o", "\u001b[0;32m$ vibe ai silence-cut demo-output/step1-clean.mp4 -o demo-output/step2-cut.mp4 --noise -35 --min-duration 0.5\u001b[0m\r\n\u001b[2m  (dry-run: skipped)\u001b[0m\r\n"]
[13.154, "o", "\r\n"]
[13.154, "o", "\u001b[2m  Detected 12 silent segments (total: 18.4s)\u001b[0m\r\n"]
[13.154, "o", "\u001b[2m  Removed 12 segments, saved 18.4s\u001b[0m\r\n"]
[13.154, "o", "\u001b[2m  Duration: 62.0s -> 43.6s (-29.7%)\u001b[0m\r\n"]
[13.154, "o", "\u001b[0;32m  Trimmed: step2-cut.mp4\u001b[0m\r\n"]
[13.154, "o", "\r\n"]
[13.662, "o", "\u001b[2m# Step 3: Transcribe + burn captions\u001b[0m\r\n\u001b[0;32m$ vibe ai caption demo-output/step2-cut.mp4 -o demo-output/step3-captioned.mp4 --style bold\u001b[0m\r\n"]
[13.662, "o", "\u001b[2m  (dry-run: skipped)\u001b[0m\r\n"]
[13.662, "o", "\r\n"]
[13.662, "o", "\u001b[2m  Transcribing with Whisper...\u001b[0m\r\n\u001b[2m  Found 34 segments (43.6s)\u001b[0m\r\n"]
[13.662, "o", "\u001b[2m  Burning captions with style: bold (white, black outline)\u001b[0m\r\n"]
[13.662, "o", "\u001b[0;32m  Captioned: step3-captioned.mp4\u001b[0m\r\n\r\n"]
[14.174, "o", "\u001b[2m# Step 4: Add fade in/out effects\u001b[0m\r\n"]
[14.174, "o", "\u001b[0;32m$ vibe ai fade demo-output/step3-captioned.mp4 -o demo-output/step4-final.mp4 --fade-in 1.0 --fade-out 1.5\u001b[0m\r\n"]
[14.175, "o", "\u001b[2m  (dry-run: skipped)\u001b[0m\r\n\r\n"]
[14.175, "o", "\u001b[2m  Applied: fade-in 1.0s (video+audio), fade-out 1.5s (video+audio)\u001b[0m\r\n\u001b[0;32m  Final: step4-final.mp4\u001b[0m\r\n"]
[14.175, "o", "\r\n\r\n"]
[14.175, "o", "\u001b[2m# 4 commands, done: denoise \u2192 silence cut \u2192 captions \u2192 fade\u001b[0m\r\n"]
[14.175, "o", "\u001b[2m# 62s raw \u2192 43.6s polished (zero manual editing)\u001b[0m\r\n"]
[16.184, "o", "\r\n\u001b[44m\u001b[1;37m                                                                \r\n"]
[16.184, "o", "                 ACT 3: Let the Agent Handle It                 \r\n                                                                \u001b[0m\r\n\r\n"]
[16.184, "o", "\u001b[2m# Let the agent handle it \u2014 give complex tasks in plain English\u001b[0m\r\n"]
[16.184, "o", "\r\n"]
[17.692, "o", "\u001b[0;32m$ vibe agent -i \"Analyze demo-output/sample.mp4, find the best frame for a thumbnail, extract it, and generate captions for the video.\" -v\u001b[0m\r\n\r\n"]
[17.692, "o", "\u001b[2m# Agent executing autonomously...\u001b[0m\r\n"]
[17.693, "o", "\r\n\u001b[0;35m  [Agent] Planning: 3 tasks identified\u001b[0m\r\n"]
[18.301, "o", "\u001b[0;35m  [Agent] Step 1: Calling ai_analyze...\u001b[0m\r\n"]
[19.111, "o", "\u001b[2m          Video: 43.6s, 1080p, 30fps\u001b[0m\r\n"]
[19.111, "o", "\u001b[2m          Content: tech product demo, speaker with screen recording\u001b[0m\r\n"]
[19.111, "o", "\u001b[2m          Audio: clear speech, minimal background noise\u001b[0m\r\n"]
[19.622, "o", "\u001b[0;35m  [Agent] Step 2: Calling ai_thumbnail --best-frame...\u001b[0m\r\n"]
[20.436, "o", "\u001b[2m          Analyzed 15 candidate frames\u001b[0m\r\n\u001b[2m          Best frame: 00:00:12.4 (score: 0.94)\u001b[0m\r\n"]
[20.436, "o", "\u001b[2m          Saved: demo-output/thumbnail.png (1920x1080)\u001b[0m\r\n"]
[20.948, "o", "\u001b[0;35m  [Agent] Step 3: Calling ai_caption...\u001b[0m\r\n"]
[21.757, "o", "\u001b[2m          Transcribed 34 segments\u001b[0m\r\n\u001b[2m          Burned captions with style: bold\u001b[0m\r\n"]
[21.757, "o", "\u001b[2m          Output: demo-output/captioned.mp4\u001b[0m\r\n"]
[22.269, "o", "\r\n"]
[22.269, "o", "\u001b[0;35m  [Agent] Done! Completed 3 tool calls autonomously.\u001b[0m\r\n\r\n"]
[22.269, "o", "\u001b[2m# One sentence in \u2192 Agent analyzes, extracts thumbnail, generates captions autonomously\u001b[0m\r\n"]
[24.278, "o", "\r\n\u001b[44m\u001b[1;37m"]
[24.278, "o", "                                                                \r\n"]
[24.278, "o", "                ACT 4: Motion Graphics Pipeline                 \r\n                                                                "]
[24.278, "o", "\u001b[0m\r\n"]
[24.278, "o", "\r\n"]
[24.278, "o", "\u001b[2m# Natural language to motion graphics \u2014 Claude writes Remotion TSX and renders it\u001b[0m\r\n\r\n"]
[25.789, "o", "\u001b[2m# Step 1: Generate a title card from plain English\u001b[0m\r\n\r\n"]
[25.789, "o", "\u001b[0;32m$ vibe ai motion \\\u001b[0m\r\n\u001b[0;32m    \"cinematic title card with 'VIBEFRAME' text, spring bounce from zero to full size, gold gradient color, particle effects in background\" \\\u001b[0m\r\n"]
[25.789, "o", "\u001b[0;32m    --render -o demo-output/title.webm\u001b[0m\r\n"]
[25.789, "o", "\r\n\u001b[2m# Generating motion graphic...\u001b[0m\r\n\r\n\u001b[2m  [Claude] Generating Remotion TSX component...\u001b[0m\r\n"]
[26.602, "o", "\u001b[2m          import { spring, useCurrentFrame } from 'remotion';\u001b[0m\r\n\u001b[2m          // 47 lines of React motion graphics code\u001b[0m\r\n"]
[27.116, "o", "\u001b[2m  [Render] Scaffolding temp project...\u001b[0m\r\n"]
[27.726, "o", "\u001b[2m  [Render] npx remotion render \u2192 title.webm (1920x1080, 5s, 30fps)\u001b[0m\r\n"]
[28.533, "o", "\r\n"]
[28.533, "o", "\u001b[0;32m  Motion graphic rendered: demo-output/title.webm\u001b[0m\r\n\r\n"]
[30.048, "o", "\u001b[2m# Step 2: Composite a lower-third overlay onto video\u001b[0m\r\n\r\n"]
[30.048, "o", "\u001b[0;32m$ vibe ai motion \\\u001b[0m\r\n"]
[30.048, "o", "\u001b[0;32m    \"lower-third title: 'Kiyeon, CEO' with smooth slide-in from left, semi-transparent dark background bar\" \\\u001b[0m\r\n\u001b[0;32m    --video demo-output/sample.mp4 -o demo-output/with-title.mp4\u001b[0m\r\n\r\n\u001b[2m# Compositing overlay...\u001b[0m\r\n\r\n\u001b[2m  [Claude] Generating Remotion TSX component...\u001b[0m\r\n"]
[30.859, "o", "\u001b[2m          // Lower-third with slide-in animation\u001b[0m\r\n"]
[31.371, "o", "\u001b[2m  [Render] Rendering transparent overlay (1920x1080, 3s)...\u001b[0m\r\n"]
[31.981, "o", "\u001b[2m  [Composite] Overlaying on sample.mp4 via FFmpeg...\u001b[0m\r\n"]
[32.795, "o", "\u001b[2m          ffmpeg -i sample.mp4 -i overlay.webm -filter_complex overlay\u001b[0m\r\n"]
[33.307, "o", "\r\n"]
[33.307, "o", "\u001b[0;32m  Composited: demo-output/with-title.mp4\u001b[0m\r\n\r\n"]
[33.307, "o", "\u001b[2m# Plain English \u2192 Claude generates code \u2192 Remotion renders \u2192 FFmpeg composites\u001b[0m\r\n"]
[33.307, "o", "\u001b[2m# Motion graphics in the terminal \u2014 no After Effects needed\u001b[0m\r\n"]
[35.318, "o", "\r\n\r\n"]
[35.318, "o", "\u001b[0;36m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\r\n\r\n\u001b[1m\u001b[1;37m  VibeFrame\u001b[0m  \u001b[2mv0.17.1\u001b[0m\r\n\u001b[2m  AI-native video editing in the terminal\u001b[0m\r\n\r\n  \u001b[0;36m58\u001b[0m agent tools  \u001b[2m|\u001b[0m  \u001b[0;36m24\u001b[0m AI commands  \u001b[2m|\u001b[0m  \u001b[0;36m10\u001b[0m providers\r\n"]
[35.318, "o", "\r\n  \u001b[2mInstall:\u001b[0m  curl -fsSL https://vibeframe.dev/install.sh | bash\r\n  \u001b[2mGitHub:\u001b[0m   https://github.com/kiyeonj51/vibeframe\r\n"]
[35.318, "o", "\r\n\u001b[0;36m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m\r\n"]
[35.318, "o", "\r\n"]
[35.318, "o", "  \u001b[1;33mIf this is useful, give us a star!\u001b[0m\r\n\r\n"]
[35.319, "x", "0"]
